# ğŸ“ RAG-Based Learning & Code Assistant with Evaluation

An advanced Retrieval-Augmented Generation (RAG) application that integrates **LangChain**, **Groqâ€™s LLaMA 3**, **ChromaDB**, and **Gradio** to assist:

- ğŸ“š **Students** â€” get smart help using uploaded learning materials
- ğŸ’» **Developers** â€” ask questions based on documentation or code

âš¡ Now includes **retrieval performance evaluation**, comparison to standard RAG setups, and real-world use case examples.

---

## âœ¨ Key Features

- ğŸ“‚ Upload documents for contextual Q&A (PDF, TXT, MD, Code files)
- ğŸ’¬ Chat with Learning or Code Assistant using Gradio UI
- ğŸ§  Powered by **Groq LLaMA 3** for lightning-fast, accurate responses
- ğŸ§± Vector store via **ChromaDB**, fallback to **TF-IDF**
- ğŸ” NEW: Evaluate performance with precision, recall & MRR
- ğŸ“Š Benchmark tab for analyzing your retrieval pipeline

---

## ğŸ§  How It Works

1. Upload documents â†’ chunked via LangChain
2. Text is embedded using HuggingFace (or TF-IDF fallback)
3. Stored persistently in ChromaDB (separately for each assistant)
4. When you ask a question:
   - Retrieves top-k relevant chunks
   - Sends query + context to **Groq LLaMA 3**
   - Answer is streamed via Gradio UI

---

## ğŸ“Š Retrieval Performance Evaluation

Evaluate your assistantâ€™s retrieval quality using:

- âœ… **Precision@k**: Measures accuracy of top-k retrievals
- âœ… **Recall@k**: Measures how many relevant answers are retrieved
- âœ… **MRR** (Mean Reciprocal Rank): Measures ranking quality

ğŸ” Evaluation File Format (Upload as `.json`):
```json
[
  {
    "question": "What is overfitting in ML?",
    "keywords": ["overfitting", "training error"]
  },
  {
    "question": "Explain BFS vs DFS",
    "keywords": ["breadth", "depth", "graph"]
  }
]
```

ğŸ“ This file must be uploaded via the **Evaluation Bench** tab.

---

## ğŸ”¬ Comparison to Traditional RAG

| Feature              | This App             | Traditional RAG    |
|----------------------|----------------------|--------------------|
| Vector Store         | ChromaDB (persistent)| In-memory/None     |
| Evaluation Bench     | âœ… Yes               | âŒ No               |
| Assistant Modes      | Learning + Code      | Generic only       |
| TF-IDF Fallback      | âœ… Yes               | âŒ No               |
| Embedding Sources    | HuggingFace / TF-IDF | Usually HuggingFace|

---

## ğŸŒ Real-World Use Cases

- ğŸ‘¨â€ğŸ« Teachers uploading course syllabi for student Q&A
- ğŸ‘©â€ğŸ’» Developers analyzing API docs to answer usage questions
- ğŸ“˜ Students uploading textbooks or lecture notes for revision help
- ğŸ“ˆ Evaluating retrieval performance for different embedding models

---

## ğŸ§° Tech Stack

| Component      | Tool / Library                         |
|----------------|-----------------------------------------|
| LLM            | LLaMA 3 via [Groq API](https://console.groq.com/) |
| RAG Framework  | [LangChain](https://www.langchain.com/) |
| Embeddings     | HuggingFace models / TF-IDF fallback    |
| Vector Store   | [ChromaDB](https://www.trychroma.com/)  |
| Interface      | [Gradio](https://www.gradio.app/)       |
| Evaluation     | Scikit-learn + custom logic             |

---

## ğŸ“ Project Structure

```
Rag_Learning_Assistant/
â”œâ”€â”€ app.py                  # Main app
â”œâ”€â”€ .env                    # API key file
â”œâ”€â”€ chroma_learning_db/     # Chroma vector DB (learning)
â”œâ”€â”€ chroma_code_db/         # Chroma vector DB (code)
â”œâ”€â”€ evaluation/             # Sample JSON evaluation files
â”œâ”€â”€ requirements.txt        # Dependencies
```

---

## âš™ï¸ Setup Instructions

### 1. Clone Repo
```bash
git clone https://github.com/ahmadsanafarooq/Data-Science-Machine-Learning-Nodebook.git
cd Data-Science-Machine-Learning-Nodebook/GEN\ AI/Rag_Learning_Assistant
```

### 2. Create Virtual Environment
```bash
python -m venv .env
source .env/bin/activate   # Windows: .env\Scripts\activate
```

### 3. Install Requirements
```bash
pip install -r requirements.txt
```

### 4. Set Groq API Key
```bash
echo "GROQ_API_KEY=your_key_here" > .env
```
Get a free key from: https://console.groq.com/

### 5. Launch the App
```bash
python app.py
```
Visit [http://localhost:7860](http://localhost:7860)

---

## ğŸ–¼ï¸ Interface Overview

### ğŸ“š Learning Tutor
- Upload `.pdf`, `.txt`, or `.md`
- Ask theory-based questions
- Receive rich, structured answers

### ğŸ’» Code Assistant
- Upload `.py`, `.js`, `.json` files
- Ask code-related queries
- Get explanations, snippets, etc.

### ğŸ“Š Evaluation Bench
- Upload `.json` with questions/keywords
- Choose assistant mode
- View precision, recall, MRR, config summary

---

## ğŸ“ Supported File Types

| Assistant        | Accepted File Types           |
|------------------|-------------------------------|
| Learning Tutor   | `.pdf`, `.txt`, `.md`         |
| Code Assistant   | `.py`, `.js`, `.json`         |
| Evaluation Bench | `.json`                       |

---

## ğŸ’¬ Sample Queries

**Learning Tutor**  
> _"What is gradient descent in machine learning?"_

**Code Assistant**  
> _"What does this Flask route do in app.py?"_

---



Install via:
```bash
pip install -r requirements.txt
```

---

## ğŸ›¡ License

MIT License â€” free to use, modify, and distribute.

---

## ğŸ™Œ Credits

- ğŸ‘¨â€ğŸ’» Developed by [Ahmad Sana Farooq](https://github.com/ahmadsanafarooq)
- ğŸ’¡ Powered by:
  - [LangChain](https://www.langchain.com/)
  - [Groq API](https://console.groq.com/)
  - [ChromaDB](https://www.trychroma.com/)
  - [Gradio](https://www.gradio.app/)
  - [HuggingFace Sentence Transformers](https://www.sbert.net/)

---

## ğŸ”— Connect

- ğŸŒ GitHub: [@ahmadsanafarooq](https://github.com/ahmadsanafarooq)
- ğŸ“„ LinkedIn: [LinkedIn Profile](https://www.linkedin.com/in/ahmad-sana-farooq/)
